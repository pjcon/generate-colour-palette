{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4f89f40-fe30-4f2f-afac-5b006f0e670f",
   "metadata": {},
   "source": [
    "# Pseudo\n",
    "- Select points in RGB\n",
    "- For each point, find k nearest neighbours assume evenly distributed\n",
    "- Score based on difference between\n",
    "\n",
    "# Focus\n",
    "- Minimise class instantiation\n",
    "- Numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a174a72e-382c-408b-8a3a-bc389b3e325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fcd3b4e-de69-45da-9e54-769c82abfc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3b70e31-23f5-4f42-b142-ab2f04197e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_points = np.random.random(size=[N, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d96ccff7-c920-4d9e-bebb-444f1148782a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45221969, 0.88807475, 0.48498694],\n",
       "       [0.07916363, 0.84307152, 0.60840341],\n",
       "       [0.25219011, 0.17505316, 0.22348611],\n",
       "       [0.96849772, 0.42076737, 0.68864667],\n",
       "       [0.47782062, 0.24419521, 0.26092017],\n",
       "       [0.81078311, 0.3070404 , 0.98801979],\n",
       "       [0.44567367, 0.19211148, 0.9953147 ],\n",
       "       [0.26849204, 0.94067574, 0.18614681],\n",
       "       [0.44718872, 0.14234202, 0.25236196],\n",
       "       [0.76068446, 0.08646759, 0.62321276]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50da59b0-a61d-41de-8fb5-0c0a76b0a2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "Collecting colormath\n",
      "  Using cached colormath-3.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /home/connorjp/.local/lib/python3.9/site-packages (from colormath) (1.20.3)\n",
      "Collecting networkx>=2.0\n",
      "  Using cached networkx-2.5.1-py3-none-any.whl (1.6 MB)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /home/connorjp/.local/lib/python3.9/site-packages (from networkx>=2.0->colormath) (4.4.2)\n",
      "Installing collected packages: networkx, colormath\n",
      "Successfully installed colormath-3.0.0 networkx-2.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install colormath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75eabbdc-32ca-4a0c-a94c-a335f1221f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from colormath.color_objects import LabColor, sRGBColor\n",
    "from colormath.color_diff import delta_e_cie1994\n",
    "from colormath.color_conversions import convert_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ce3bd4f-3767-440b-990f-9f19e7a34b29",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class sRGBColor in module colormath.color_objects:\n",
      "\n",
      "class sRGBColor(BaseRGBColor)\n",
      " |  sRGBColor(rgb_r, rgb_g, rgb_b, is_upscaled=False)\n",
      " |  \n",
      " |  Represents an sRGB color.\n",
      " |  \n",
      " |  .. note:: If you pass in upscaled values, we automatically scale them\n",
      " |      down to 0.0-1.0. If you need the old upscaled values, you can\n",
      " |      retrieve them with :py:meth:`get_upscaled_value_tuple`.\n",
      " |  \n",
      " |  :ivar float rgb_r: R coordinate\n",
      " |  :ivar float rgb_g: G coordinate\n",
      " |  :ivar float rgb_b: B coordinate\n",
      " |  :ivar bool is_upscaled: If True, RGB values are between 1-255. If False,\n",
      " |      0.0-1.0.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      sRGBColor\n",
      " |      BaseRGBColor\n",
      " |      ColorBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  conversion_matrices = {'rgb_to_xyz': array([[0.412424 , 0.357579 , 0.1...\n",
      " |  \n",
      " |  native_illuminant = 'd65'\n",
      " |  \n",
      " |  rgb_gamma = 2.2\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseRGBColor:\n",
      " |  \n",
      " |  __init__(self, rgb_r, rgb_g, rgb_b, is_upscaled=False)\n",
      " |      :param float rgb_r: R coordinate. 0...1. 1-255 if is_upscaled=True.\n",
      " |      :param float rgb_g: G coordinate. 0...1. 1-255 if is_upscaled=True.\n",
      " |      :param float rgb_b: B coordinate. 0...1. 1-255 if is_upscaled=True.\n",
      " |      :keyword bool is_upscaled: If False, RGB coordinate values are\n",
      " |          beteween 0.0 and 1.0. If True, RGB values are between 1 and 255.\n",
      " |  \n",
      " |  get_rgb_hex(self)\n",
      " |      Converts the RGB value to a hex value in the form of: #RRGGBB\n",
      " |      \n",
      " |      :rtype: str\n",
      " |  \n",
      " |  get_upscaled_value_tuple(self)\n",
      " |      Scales an RGB color object from decimal 0.0-1.0 to int 0-255.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from BaseRGBColor:\n",
      " |  \n",
      " |  new_from_rgb_hex(hex_str) from builtins.type\n",
      " |      Converts an RGB hex string like #RRGGBB and assigns the values to\n",
      " |      this sRGBColor object.\n",
      " |      \n",
      " |      :rtype: sRGBColor\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseRGBColor:\n",
      " |  \n",
      " |  clamped_rgb_b\n",
      " |      The clamped (0.0-1.0) B value.\n",
      " |  \n",
      " |  clamped_rgb_g\n",
      " |      The clamped (0.0-1.0) G value.\n",
      " |  \n",
      " |  clamped_rgb_r\n",
      " |      The clamped (0.0-1.0) R value.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from BaseRGBColor:\n",
      " |  \n",
      " |  VALUES = ['rgb_r', 'rgb_g', 'rgb_b']\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ColorBase:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      String representation of the object.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      String representation of the color.\n",
      " |  \n",
      " |  get_value_tuple(self)\n",
      " |      Returns a tuple of the color's values (in order). For example,\n",
      " |      an LabColor object will return (lab_l, lab_a, lab_b), where each\n",
      " |      member of the tuple is the float value for said variable.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from ColorBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sRGBColor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b28e31aa-c442-4ac9-8311-78022e52302d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.41 µs ± 11.4 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sRGBColor(*rgb_points[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19ff5c92-65d6-4a26-af92-f41a65dc9111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sRGBColor(rgb_r=0.4522196878124888,rgb_g=0.8880747473857142,rgb_b=0.4849869429608783)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = sRGBColor(*rgb_points[0])\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3a4169c5-c5f5-4ed2-9947-76443a6209e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#73e27c'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "khx = k.get_rgb_hex()\n",
    "khx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d9d2e259-d542-4679-9173-e576fb64e93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.53 µs ± 6.53 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "k.new_from_rgb_hex(khx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a806787a-9184-479f-a24a-181deba56394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.9 µs ± 204 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "convert_color(k, LabColor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efe3d128-dc8a-41d9-a13b-724b4f83c667",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = convert_color(k, LabColor)\n",
    "l2 = convert_color(k, LabColor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e70b9de-9642-4545-afc1-220121296af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.8 µs ± 767 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "delta_e_cie1994(l1,l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df0913c3-91ec-4c83-bb15-aaa0ca0a2221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.6.3-cp39-cp39-manylinux1_x86_64.whl (27.3 MB)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /home/connorjp/.local/lib/python3.9/site-packages (from scipy) (1.20.3)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.6.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e76676f-776d-4a3e-9d52-9c124cc58814",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b22ea4ec-2189-4d36-b38b-7c2d660582a1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function minimize in module scipy.optimize._minimize:\n",
      "\n",
      "minimize(fun, x0, args=(), method=None, jac=None, hess=None, hessp=None, bounds=None, constraints=(), tol=None, callback=None, options=None)\n",
      "    Minimization of scalar function of one or more variables.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    fun : callable\n",
      "        The objective function to be minimized.\n",
      "    \n",
      "            ``fun(x, *args) -> float``\n",
      "    \n",
      "        where ``x`` is an 1-D array with shape (n,) and ``args``\n",
      "        is a tuple of the fixed parameters needed to completely\n",
      "        specify the function.\n",
      "    x0 : ndarray, shape (n,)\n",
      "        Initial guess. Array of real elements of size (n,),\n",
      "        where 'n' is the number of independent variables.\n",
      "    args : tuple, optional\n",
      "        Extra arguments passed to the objective function and its\n",
      "        derivatives (`fun`, `jac` and `hess` functions).\n",
      "    method : str or callable, optional\n",
      "        Type of solver.  Should be one of\n",
      "    \n",
      "            - 'Nelder-Mead' :ref:`(see here) <optimize.minimize-neldermead>`\n",
      "            - 'Powell'      :ref:`(see here) <optimize.minimize-powell>`\n",
      "            - 'CG'          :ref:`(see here) <optimize.minimize-cg>`\n",
      "            - 'BFGS'        :ref:`(see here) <optimize.minimize-bfgs>`\n",
      "            - 'Newton-CG'   :ref:`(see here) <optimize.minimize-newtoncg>`\n",
      "            - 'L-BFGS-B'    :ref:`(see here) <optimize.minimize-lbfgsb>`\n",
      "            - 'TNC'         :ref:`(see here) <optimize.minimize-tnc>`\n",
      "            - 'COBYLA'      :ref:`(see here) <optimize.minimize-cobyla>`\n",
      "            - 'SLSQP'       :ref:`(see here) <optimize.minimize-slsqp>`\n",
      "            - 'trust-constr':ref:`(see here) <optimize.minimize-trustconstr>`\n",
      "            - 'dogleg'      :ref:`(see here) <optimize.minimize-dogleg>`\n",
      "            - 'trust-ncg'   :ref:`(see here) <optimize.minimize-trustncg>`\n",
      "            - 'trust-exact' :ref:`(see here) <optimize.minimize-trustexact>`\n",
      "            - 'trust-krylov' :ref:`(see here) <optimize.minimize-trustkrylov>`\n",
      "            - custom - a callable object (added in version 0.14.0),\n",
      "              see below for description.\n",
      "    \n",
      "        If not given, chosen to be one of ``BFGS``, ``L-BFGS-B``, ``SLSQP``,\n",
      "        depending if the problem has constraints or bounds.\n",
      "    jac : {callable,  '2-point', '3-point', 'cs', bool}, optional\n",
      "        Method for computing the gradient vector. Only for CG, BFGS,\n",
      "        Newton-CG, L-BFGS-B, TNC, SLSQP, dogleg, trust-ncg, trust-krylov,\n",
      "        trust-exact and trust-constr.\n",
      "        If it is a callable, it should be a function that returns the gradient\n",
      "        vector:\n",
      "    \n",
      "            ``jac(x, *args) -> array_like, shape (n,)``\n",
      "    \n",
      "        where ``x`` is an array with shape (n,) and ``args`` is a tuple with\n",
      "        the fixed parameters. If `jac` is a Boolean and is True, `fun` is\n",
      "        assumed to return and objective and gradient as an ``(f, g)`` tuple.\n",
      "        Methods 'Newton-CG', 'trust-ncg', 'dogleg', 'trust-exact', and\n",
      "        'trust-krylov' require that either a callable be supplied, or that\n",
      "        `fun` return the objective and gradient.\n",
      "        If None or False, the gradient will be estimated using 2-point finite\n",
      "        difference estimation with an absolute step size.\n",
      "        Alternatively, the keywords  {'2-point', '3-point', 'cs'} can be used\n",
      "        to select a finite difference scheme for numerical estimation of the\n",
      "        gradient with a relative step size. These finite difference schemes\n",
      "        obey any specified `bounds`.\n",
      "    hess : {callable, '2-point', '3-point', 'cs', HessianUpdateStrategy}, optional\n",
      "        Method for computing the Hessian matrix. Only for Newton-CG, dogleg,\n",
      "        trust-ncg,  trust-krylov, trust-exact and trust-constr. If it is\n",
      "        callable, it should return the  Hessian matrix:\n",
      "    \n",
      "            ``hess(x, *args) -> {LinearOperator, spmatrix, array}, (n, n)``\n",
      "    \n",
      "        where x is a (n,) ndarray and `args` is a tuple with the fixed\n",
      "        parameters. LinearOperator and sparse matrix returns are\n",
      "        allowed only for 'trust-constr' method. Alternatively, the keywords\n",
      "        {'2-point', '3-point', 'cs'} select a finite difference scheme\n",
      "        for numerical estimation. Or, objects implementing\n",
      "        `HessianUpdateStrategy` interface can be used to approximate\n",
      "        the Hessian. Available quasi-Newton methods implementing\n",
      "        this interface are:\n",
      "    \n",
      "            - `BFGS`;\n",
      "            - `SR1`.\n",
      "    \n",
      "        Whenever the gradient is estimated via finite-differences,\n",
      "        the Hessian cannot be estimated with options\n",
      "        {'2-point', '3-point', 'cs'} and needs to be\n",
      "        estimated using one of the quasi-Newton strategies.\n",
      "        Finite-difference options {'2-point', '3-point', 'cs'} and\n",
      "        `HessianUpdateStrategy` are available only for 'trust-constr' method.\n",
      "    hessp : callable, optional\n",
      "        Hessian of objective function times an arbitrary vector p. Only for\n",
      "        Newton-CG, trust-ncg, trust-krylov, trust-constr.\n",
      "        Only one of `hessp` or `hess` needs to be given.  If `hess` is\n",
      "        provided, then `hessp` will be ignored.  `hessp` must compute the\n",
      "        Hessian times an arbitrary vector:\n",
      "    \n",
      "            ``hessp(x, p, *args) ->  ndarray shape (n,)``\n",
      "    \n",
      "        where x is a (n,) ndarray, p is an arbitrary vector with\n",
      "        dimension (n,) and `args` is a tuple with the fixed\n",
      "        parameters.\n",
      "    bounds : sequence or `Bounds`, optional\n",
      "        Bounds on variables for L-BFGS-B, TNC, SLSQP, Powell, and\n",
      "        trust-constr methods. There are two ways to specify the bounds:\n",
      "    \n",
      "            1. Instance of `Bounds` class.\n",
      "            2. Sequence of ``(min, max)`` pairs for each element in `x`. None\n",
      "               is used to specify no bound.\n",
      "    \n",
      "    constraints : {Constraint, dict} or List of {Constraint, dict}, optional\n",
      "        Constraints definition (only for COBYLA, SLSQP and trust-constr).\n",
      "    \n",
      "        Constraints for 'trust-constr' are defined as a single object or a\n",
      "        list of objects specifying constraints to the optimization problem.\n",
      "        Available constraints are:\n",
      "    \n",
      "            - `LinearConstraint`\n",
      "            - `NonlinearConstraint`\n",
      "    \n",
      "        Constraints for COBYLA, SLSQP are defined as a list of dictionaries.\n",
      "        Each dictionary with fields:\n",
      "    \n",
      "            type : str\n",
      "                Constraint type: 'eq' for equality, 'ineq' for inequality.\n",
      "            fun : callable\n",
      "                The function defining the constraint.\n",
      "            jac : callable, optional\n",
      "                The Jacobian of `fun` (only for SLSQP).\n",
      "            args : sequence, optional\n",
      "                Extra arguments to be passed to the function and Jacobian.\n",
      "    \n",
      "        Equality constraint means that the constraint function result is to\n",
      "        be zero whereas inequality means that it is to be non-negative.\n",
      "        Note that COBYLA only supports inequality constraints.\n",
      "    tol : float, optional\n",
      "        Tolerance for termination. For detailed control, use solver-specific\n",
      "        options.\n",
      "    options : dict, optional\n",
      "        A dictionary of solver options. All methods accept the following\n",
      "        generic options:\n",
      "    \n",
      "            maxiter : int\n",
      "                Maximum number of iterations to perform. Depending on the\n",
      "                method each iteration may use several function evaluations.\n",
      "            disp : bool\n",
      "                Set to True to print convergence messages.\n",
      "    \n",
      "        For method-specific options, see :func:`show_options()`.\n",
      "    callback : callable, optional\n",
      "        Called after each iteration. For 'trust-constr' it is a callable with\n",
      "        the signature:\n",
      "    \n",
      "            ``callback(xk, OptimizeResult state) -> bool``\n",
      "    \n",
      "        where ``xk`` is the current parameter vector. and ``state``\n",
      "        is an `OptimizeResult` object, with the same fields\n",
      "        as the ones from the return. If callback returns True\n",
      "        the algorithm execution is terminated.\n",
      "        For all the other methods, the signature is:\n",
      "    \n",
      "            ``callback(xk)``\n",
      "    \n",
      "        where ``xk`` is the current parameter vector.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    res : OptimizeResult\n",
      "        The optimization result represented as a ``OptimizeResult`` object.\n",
      "        Important attributes are: ``x`` the solution array, ``success`` a\n",
      "        Boolean flag indicating if the optimizer exited successfully and\n",
      "        ``message`` which describes the cause of the termination. See\n",
      "        `OptimizeResult` for a description of other attributes.\n",
      "    \n",
      "    See also\n",
      "    --------\n",
      "    minimize_scalar : Interface to minimization algorithms for scalar\n",
      "        univariate functions\n",
      "    show_options : Additional options accepted by the solvers\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    This section describes the available solvers that can be selected by the\n",
      "    'method' parameter. The default method is *BFGS*.\n",
      "    \n",
      "    **Unconstrained minimization**\n",
      "    \n",
      "    Method :ref:`Nelder-Mead <optimize.minimize-neldermead>` uses the\n",
      "    Simplex algorithm [1]_, [2]_. This algorithm is robust in many\n",
      "    applications. However, if numerical computation of derivative can be\n",
      "    trusted, other algorithms using the first and/or second derivatives\n",
      "    information might be preferred for their better performance in\n",
      "    general.\n",
      "    \n",
      "    Method :ref:`CG <optimize.minimize-cg>` uses a nonlinear conjugate\n",
      "    gradient algorithm by Polak and Ribiere, a variant of the\n",
      "    Fletcher-Reeves method described in [5]_ pp.120-122. Only the\n",
      "    first derivatives are used.\n",
      "    \n",
      "    Method :ref:`BFGS <optimize.minimize-bfgs>` uses the quasi-Newton\n",
      "    method of Broyden, Fletcher, Goldfarb, and Shanno (BFGS) [5]_\n",
      "    pp. 136. It uses the first derivatives only. BFGS has proven good\n",
      "    performance even for non-smooth optimizations. This method also\n",
      "    returns an approximation of the Hessian inverse, stored as\n",
      "    `hess_inv` in the OptimizeResult object.\n",
      "    \n",
      "    Method :ref:`Newton-CG <optimize.minimize-newtoncg>` uses a\n",
      "    Newton-CG algorithm [5]_ pp. 168 (also known as the truncated\n",
      "    Newton method). It uses a CG method to the compute the search\n",
      "    direction. See also *TNC* method for a box-constrained\n",
      "    minimization with a similar algorithm. Suitable for large-scale\n",
      "    problems.\n",
      "    \n",
      "    Method :ref:`dogleg <optimize.minimize-dogleg>` uses the dog-leg\n",
      "    trust-region algorithm [5]_ for unconstrained minimization. This\n",
      "    algorithm requires the gradient and Hessian; furthermore the\n",
      "    Hessian is required to be positive definite.\n",
      "    \n",
      "    Method :ref:`trust-ncg <optimize.minimize-trustncg>` uses the\n",
      "    Newton conjugate gradient trust-region algorithm [5]_ for\n",
      "    unconstrained minimization. This algorithm requires the gradient\n",
      "    and either the Hessian or a function that computes the product of\n",
      "    the Hessian with a given vector. Suitable for large-scale problems.\n",
      "    \n",
      "    Method :ref:`trust-krylov <optimize.minimize-trustkrylov>` uses\n",
      "    the Newton GLTR trust-region algorithm [14]_, [15]_ for unconstrained\n",
      "    minimization. This algorithm requires the gradient\n",
      "    and either the Hessian or a function that computes the product of\n",
      "    the Hessian with a given vector. Suitable for large-scale problems.\n",
      "    On indefinite problems it requires usually less iterations than the\n",
      "    `trust-ncg` method and is recommended for medium and large-scale problems.\n",
      "    \n",
      "    Method :ref:`trust-exact <optimize.minimize-trustexact>`\n",
      "    is a trust-region method for unconstrained minimization in which\n",
      "    quadratic subproblems are solved almost exactly [13]_. This\n",
      "    algorithm requires the gradient and the Hessian (which is\n",
      "    *not* required to be positive definite). It is, in many\n",
      "    situations, the Newton method to converge in fewer iteraction\n",
      "    and the most recommended for small and medium-size problems.\n",
      "    \n",
      "    **Bound-Constrained minimization**\n",
      "    \n",
      "    Method :ref:`L-BFGS-B <optimize.minimize-lbfgsb>` uses the L-BFGS-B\n",
      "    algorithm [6]_, [7]_ for bound constrained minimization.\n",
      "    \n",
      "    Method :ref:`Powell <optimize.minimize-powell>` is a modification\n",
      "    of Powell's method [3]_, [4]_ which is a conjugate direction\n",
      "    method. It performs sequential one-dimensional minimizations along\n",
      "    each vector of the directions set (`direc` field in `options` and\n",
      "    `info`), which is updated at each iteration of the main\n",
      "    minimization loop. The function need not be differentiable, and no\n",
      "    derivatives are taken. If bounds are not provided, then an\n",
      "    unbounded line search will be used. If bounds are provided and\n",
      "    the initial guess is within the bounds, then every function\n",
      "    evaluation throughout the minimization procedure will be within\n",
      "    the bounds. If bounds are provided, the initial guess is outside\n",
      "    the bounds, and `direc` is full rank (default has full rank), then\n",
      "    some function evaluations during the first iteration may be\n",
      "    outside the bounds, but every function evaluation after the first\n",
      "    iteration will be within the bounds. If `direc` is not full rank,\n",
      "    then some parameters may not be optimized and the solution is not\n",
      "    guaranteed to be within the bounds.\n",
      "    \n",
      "    Method :ref:`TNC <optimize.minimize-tnc>` uses a truncated Newton\n",
      "    algorithm [5]_, [8]_ to minimize a function with variables subject\n",
      "    to bounds. This algorithm uses gradient information; it is also\n",
      "    called Newton Conjugate-Gradient. It differs from the *Newton-CG*\n",
      "    method described above as it wraps a C implementation and allows\n",
      "    each variable to be given upper and lower bounds.\n",
      "    \n",
      "    **Constrained Minimization**\n",
      "    \n",
      "    Method :ref:`COBYLA <optimize.minimize-cobyla>` uses the\n",
      "    Constrained Optimization BY Linear Approximation (COBYLA) method\n",
      "    [9]_, [10]_, [11]_. The algorithm is based on linear\n",
      "    approximations to the objective function and each constraint. The\n",
      "    method wraps a FORTRAN implementation of the algorithm. The\n",
      "    constraints functions 'fun' may return either a single number\n",
      "    or an array or list of numbers.\n",
      "    \n",
      "    Method :ref:`SLSQP <optimize.minimize-slsqp>` uses Sequential\n",
      "    Least SQuares Programming to minimize a function of several\n",
      "    variables with any combination of bounds, equality and inequality\n",
      "    constraints. The method wraps the SLSQP Optimization subroutine\n",
      "    originally implemented by Dieter Kraft [12]_. Note that the\n",
      "    wrapper handles infinite values in bounds by converting them into\n",
      "    large floating values.\n",
      "    \n",
      "    Method :ref:`trust-constr <optimize.minimize-trustconstr>` is a\n",
      "    trust-region algorithm for constrained optimization. It swiches\n",
      "    between two implementations depending on the problem definition.\n",
      "    It is the most versatile constrained minimization algorithm\n",
      "    implemented in SciPy and the most appropriate for large-scale problems.\n",
      "    For equality constrained problems it is an implementation of Byrd-Omojokun\n",
      "    Trust-Region SQP method described in [17]_ and in [5]_, p. 549. When\n",
      "    inequality constraints  are imposed as well, it swiches to the trust-region\n",
      "    interior point  method described in [16]_. This interior point algorithm,\n",
      "    in turn, solves inequality constraints by introducing slack variables\n",
      "    and solving a sequence of equality-constrained barrier problems\n",
      "    for progressively smaller values of the barrier parameter.\n",
      "    The previously described equality constrained SQP method is\n",
      "    used to solve the subproblems with increasing levels of accuracy\n",
      "    as the iterate gets closer to a solution.\n",
      "    \n",
      "    **Finite-Difference Options**\n",
      "    \n",
      "    For Method :ref:`trust-constr <optimize.minimize-trustconstr>`\n",
      "    the gradient and the Hessian may be approximated using\n",
      "    three finite-difference schemes: {'2-point', '3-point', 'cs'}.\n",
      "    The scheme 'cs' is, potentially, the most accurate but it\n",
      "    requires the function to correctly handles complex inputs and to\n",
      "    be differentiable in the complex plane. The scheme '3-point' is more\n",
      "    accurate than '2-point' but requires twice as many operations.\n",
      "    \n",
      "    **Custom minimizers**\n",
      "    \n",
      "    It may be useful to pass a custom minimization method, for example\n",
      "    when using a frontend to this method such as `scipy.optimize.basinhopping`\n",
      "    or a different library.  You can simply pass a callable as the ``method``\n",
      "    parameter.\n",
      "    \n",
      "    The callable is called as ``method(fun, x0, args, **kwargs, **options)``\n",
      "    where ``kwargs`` corresponds to any other parameters passed to `minimize`\n",
      "    (such as `callback`, `hess`, etc.), except the `options` dict, which has\n",
      "    its contents also passed as `method` parameters pair by pair.  Also, if\n",
      "    `jac` has been passed as a bool type, `jac` and `fun` are mangled so that\n",
      "    `fun` returns just the function values and `jac` is converted to a function\n",
      "    returning the Jacobian.  The method shall return an `OptimizeResult`\n",
      "    object.\n",
      "    \n",
      "    The provided `method` callable must be able to accept (and possibly ignore)\n",
      "    arbitrary parameters; the set of parameters accepted by `minimize` may\n",
      "    expand in future versions and then these parameters will be passed to\n",
      "    the method.  You can find an example in the scipy.optimize tutorial.\n",
      "    \n",
      "    .. versionadded:: 0.11.0\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Nelder, J A, and R Mead. 1965. A Simplex Method for Function\n",
      "        Minimization. The Computer Journal 7: 308-13.\n",
      "    .. [2] Wright M H. 1996. Direct search methods: Once scorned, now\n",
      "        respectable, in Numerical Analysis 1995: Proceedings of the 1995\n",
      "        Dundee Biennial Conference in Numerical Analysis (Eds. D F\n",
      "        Griffiths and G A Watson). Addison Wesley Longman, Harlow, UK.\n",
      "        191-208.\n",
      "    .. [3] Powell, M J D. 1964. An efficient method for finding the minimum of\n",
      "       a function of several variables without calculating derivatives. The\n",
      "       Computer Journal 7: 155-162.\n",
      "    .. [4] Press W, S A Teukolsky, W T Vetterling and B P Flannery.\n",
      "       Numerical Recipes (any edition), Cambridge University Press.\n",
      "    .. [5] Nocedal, J, and S J Wright. 2006. Numerical Optimization.\n",
      "       Springer New York.\n",
      "    .. [6] Byrd, R H and P Lu and J. Nocedal. 1995. A Limited Memory\n",
      "       Algorithm for Bound Constrained Optimization. SIAM Journal on\n",
      "       Scientific and Statistical Computing 16 (5): 1190-1208.\n",
      "    .. [7] Zhu, C and R H Byrd and J Nocedal. 1997. L-BFGS-B: Algorithm\n",
      "       778: L-BFGS-B, FORTRAN routines for large scale bound constrained\n",
      "       optimization. ACM Transactions on Mathematical Software 23 (4):\n",
      "       550-560.\n",
      "    .. [8] Nash, S G. Newton-Type Minimization Via the Lanczos Method.\n",
      "       1984. SIAM Journal of Numerical Analysis 21: 770-778.\n",
      "    .. [9] Powell, M J D. A direct search optimization method that models\n",
      "       the objective and constraint functions by linear interpolation.\n",
      "       1994. Advances in Optimization and Numerical Analysis, eds. S. Gomez\n",
      "       and J-P Hennart, Kluwer Academic (Dordrecht), 51-67.\n",
      "    .. [10] Powell M J D. Direct search algorithms for optimization\n",
      "       calculations. 1998. Acta Numerica 7: 287-336.\n",
      "    .. [11] Powell M J D. A view of algorithms for optimization without\n",
      "       derivatives. 2007.Cambridge University Technical Report DAMTP\n",
      "       2007/NA03\n",
      "    .. [12] Kraft, D. A software package for sequential quadratic\n",
      "       programming. 1988. Tech. Rep. DFVLR-FB 88-28, DLR German Aerospace\n",
      "       Center -- Institute for Flight Mechanics, Koln, Germany.\n",
      "    .. [13] Conn, A. R., Gould, N. I., and Toint, P. L.\n",
      "       Trust region methods. 2000. Siam. pp. 169-200.\n",
      "    .. [14] F. Lenders, C. Kirches, A. Potschka: \"trlib: A vector-free\n",
      "       implementation of the GLTR method for iterative solution of\n",
      "       the trust region problem\", :arxiv:`1611.04718`\n",
      "    .. [15] N. Gould, S. Lucidi, M. Roma, P. Toint: \"Solving the\n",
      "       Trust-Region Subproblem using the Lanczos Method\",\n",
      "       SIAM J. Optim., 9(2), 504--525, (1999).\n",
      "    .. [16] Byrd, Richard H., Mary E. Hribar, and Jorge Nocedal. 1999.\n",
      "        An interior point algorithm for large-scale nonlinear  programming.\n",
      "        SIAM Journal on Optimization 9.4: 877-900.\n",
      "    .. [17] Lalee, Marucha, Jorge Nocedal, and Todd Plantega. 1998. On the\n",
      "        implementation of an algorithm for large-scale equality constrained\n",
      "        optimization. SIAM Journal on Optimization 8.3: 682-706.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Let us consider the problem of minimizing the Rosenbrock function. This\n",
      "    function (and its respective derivatives) is implemented in `rosen`\n",
      "    (resp. `rosen_der`, `rosen_hess`) in the `scipy.optimize`.\n",
      "    \n",
      "    >>> from scipy.optimize import minimize, rosen, rosen_der\n",
      "    \n",
      "    A simple application of the *Nelder-Mead* method is:\n",
      "    \n",
      "    >>> x0 = [1.3, 0.7, 0.8, 1.9, 1.2]\n",
      "    >>> res = minimize(rosen, x0, method='Nelder-Mead', tol=1e-6)\n",
      "    >>> res.x\n",
      "    array([ 1.,  1.,  1.,  1.,  1.])\n",
      "    \n",
      "    Now using the *BFGS* algorithm, using the first derivative and a few\n",
      "    options:\n",
      "    \n",
      "    >>> res = minimize(rosen, x0, method='BFGS', jac=rosen_der,\n",
      "    ...                options={'gtol': 1e-6, 'disp': True})\n",
      "    Optimization terminated successfully.\n",
      "             Current function value: 0.000000\n",
      "             Iterations: 26\n",
      "             Function evaluations: 31\n",
      "             Gradient evaluations: 31\n",
      "    >>> res.x\n",
      "    array([ 1.,  1.,  1.,  1.,  1.])\n",
      "    >>> print(res.message)\n",
      "    Optimization terminated successfully.\n",
      "    >>> res.hess_inv\n",
      "    array([[ 0.00749589,  0.01255155,  0.02396251,  0.04750988,  0.09495377],  # may vary\n",
      "           [ 0.01255155,  0.02510441,  0.04794055,  0.09502834,  0.18996269],\n",
      "           [ 0.02396251,  0.04794055,  0.09631614,  0.19092151,  0.38165151],\n",
      "           [ 0.04750988,  0.09502834,  0.19092151,  0.38341252,  0.7664427 ],\n",
      "           [ 0.09495377,  0.18996269,  0.38165151,  0.7664427,   1.53713523]])\n",
      "    \n",
      "    \n",
      "    Next, consider a minimization problem with several constraints (namely\n",
      "    Example 16.4 from [5]_). The objective function is:\n",
      "    \n",
      "    >>> fun = lambda x: (x[0] - 1)**2 + (x[1] - 2.5)**2\n",
      "    \n",
      "    There are three constraints defined as:\n",
      "    \n",
      "    >>> cons = ({'type': 'ineq', 'fun': lambda x:  x[0] - 2 * x[1] + 2},\n",
      "    ...         {'type': 'ineq', 'fun': lambda x: -x[0] - 2 * x[1] + 6},\n",
      "    ...         {'type': 'ineq', 'fun': lambda x: -x[0] + 2 * x[1] + 2})\n",
      "    \n",
      "    And variables must be positive, hence the following bounds:\n",
      "    \n",
      "    >>> bnds = ((0, None), (0, None))\n",
      "    \n",
      "    The optimization problem is solved using the SLSQP method as:\n",
      "    \n",
      "    >>> res = minimize(fun, (2, 0), method='SLSQP', bounds=bnds,\n",
      "    ...                constraints=cons)\n",
      "    \n",
      "    It should converge to the theoretical solution (1.4 ,1.7).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(minimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e55a00c3-9006-40cc-8668-29265e64b544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "16f9c9ff-c314-4c5d-8ff9-c57fff3d0e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45221969, 0.88807475, 0.48498694],\n",
       "       [0.07916363, 0.84307152, 0.60840341],\n",
       "       [0.25219011, 0.17505316, 0.22348611],\n",
       "       [0.96849772, 0.42076737, 0.68864667],\n",
       "       [0.47782062, 0.24419521, 0.26092017],\n",
       "       [0.81078311, 0.3070404 , 0.98801979],\n",
       "       [0.44567367, 0.19211148, 0.9953147 ],\n",
       "       [0.26849204, 0.94067574, 0.18614681],\n",
       "       [0.44718872, 0.14234202, 0.25236196],\n",
       "       [0.76068446, 0.08646759, 0.62321276]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3a211339-2a9c-4172-9b5d-84c58b68515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tree = cKDTree(rgb_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f8909fb5-90f1-4e0b-86f1-85d21717ea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 nearest neighbours\n",
    "# find the neighbours for five random points\n",
    "dists, inds = Tree.query(np.random.random([5,3]), k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fb216463-b9f2-4260-8fc2-086194ee3418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 2],\n",
       "       [0, 3],\n",
       "       [0, 7],\n",
       "       [0, 3],\n",
       "       [7, 0]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f3f29be0-30c9-4866-b27c-105f195d4099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.1 µs ± 163 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "cKDTree(rgb_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dd6f295f-665e-4a58-ae1c-196451a3eb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.3 µs ± 282 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "Tree.query(np.random.random([5,3]), k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666e99a1-14d9-454b-8fcd-d918dba368d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a4b984e8-7efb-4db3-aa40-a005210888f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(arr):\n",
    "    return np.sqrt(np.sum(np.square(arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "677d95ee-c5bc-4898-b6c5-2fe5884af015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(lab_objs, neighbour_inds):\n",
    "    \n",
    "    # Calculate norm for all nearest differences\n",
    "    sum_diff2 = 0\n",
    "    for i, inds in enumerate(neighbour_inds):\n",
    "        for j in inds[1:]: # ignore 0th nearest colour\n",
    "            sum_diff2 += np.square(delta_e_cie1994(lab_objs[i], lab_objs[j]))\n",
    "    \n",
    "    score = -np.sqrt(sum_diff2)\n",
    "    return score\n",
    "\n",
    "def fun(C):\n",
    "    # input array of colours\n",
    "    # reshape to handle\n",
    "    N = C.size//3\n",
    "    C = C.reshape(N,3)\n",
    "    \n",
    "    # instantiate\n",
    "    labs = [convert_color(sRGBColor(*rgb), LabColor) for rgb in C]\n",
    "    \n",
    "    # nearest neighbours\n",
    "    rgb_tree = cKDTree(C)\n",
    "    _, rgb_neighbour_inds = rgb_tree.query(C, k=N)\n",
    "    \n",
    "    obj = score(labs, rgb_neighbour_inds)\n",
    "    \n",
    "    # jacobian\n",
    "    step = 0.01\n",
    "    \n",
    "    # Add 1 to each in RGB for each colour\n",
    "    # dx00, dx01, dx02, dx10, ... d colour matrix\n",
    "    labs_d = [[convert_color(sRGBColor(*np.add(rgb, np.roll([step, 0, 0], i))), LabColor) \n",
    "               for i in [0,1,2]]\n",
    "                   for rgb in C] \n",
    "    \n",
    "    def stitch(orig, newel, newind):\n",
    "        return orig[:newind] + [newel] + orig[newind+1:]\n",
    "    \n",
    "    jac = [None for i in range(np.size(labs_d))]\n",
    "    ji = 0\n",
    "    for i, lab_di in enumerate(labs_d):\n",
    "        for l in lab_di:\n",
    "            obj_d = score(stitch(labs, l, i), rgb_neighbour_inds)\n",
    "            jac[ji] = (obj_d - obj)/step\n",
    "            \n",
    "            ji += 1\n",
    "        \n",
    "    return obj, jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "21bf0595-f58d-4c8f-96fc-03317b13a847",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191 ms ± 3.37 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "_, p = fun(rgb_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "4e42e464-3a2f-4161-a670-129fc15a07c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "cd0d8b12-bc7f-400b-8cc5-b377fd7b794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = np.random.random([10,3]).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "8c6cde63-55ea-4636-a4b1-d85341643c5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.087123870849609\n"
     ]
    }
   ],
   "source": [
    "ti = time.time()\n",
    "sol = minimize(fun, pts, jac=True, method='L-BFGS-B', bounds=[(0,1) for i in pts])\n",
    "total = time.time() - ti\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "9b8c9930-56d4-4e60-a3ac-5009648d4ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: -888.4722683060419\n",
       " hess_inv: <30x30 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([   1.58632932, -104.93079655,    6.75404442,  336.47567196,\n",
       "        651.2944585 ,  432.06520214,    4.22924178,   28.39301349,\n",
       "        -43.33815443,  -23.49893606,  -91.7664435 ,    6.2756935 ,\n",
       "        336.47567196,  651.2944585 ,  432.06520214,  336.50686789,\n",
       "        651.4073017 ,  432.13031486,  -23.49893618,  -91.76655292,\n",
       "          6.27569368,    1.58635976, -104.89493359,    6.75417196,\n",
       "          1.58632932, -104.93079655,    6.75404442,    4.22924178,\n",
       "         28.39301525,  -43.33816952])\n",
       "  message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
       "     nfev: 37\n",
       "      nit: 7\n",
       "     njev: 37\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "5e9a6f02-1d03-4337-ac0e-4b079a48bf2a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function minimize in module scipy.optimize._minimize:\n",
      "\n",
      "minimize(fun, x0, args=(), method=None, jac=None, hess=None, hessp=None, bounds=None, constraints=(), tol=None, callback=None, options=None)\n",
      "    Minimization of scalar function of one or more variables.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    fun : callable\n",
      "        The objective function to be minimized.\n",
      "    \n",
      "            ``fun(x, *args) -> float``\n",
      "    \n",
      "        where ``x`` is an 1-D array with shape (n,) and ``args``\n",
      "        is a tuple of the fixed parameters needed to completely\n",
      "        specify the function.\n",
      "    x0 : ndarray, shape (n,)\n",
      "        Initial guess. Array of real elements of size (n,),\n",
      "        where 'n' is the number of independent variables.\n",
      "    args : tuple, optional\n",
      "        Extra arguments passed to the objective function and its\n",
      "        derivatives (`fun`, `jac` and `hess` functions).\n",
      "    method : str or callable, optional\n",
      "        Type of solver.  Should be one of\n",
      "    \n",
      "            - 'Nelder-Mead' :ref:`(see here) <optimize.minimize-neldermead>`\n",
      "            - 'Powell'      :ref:`(see here) <optimize.minimize-powell>`\n",
      "            - 'CG'          :ref:`(see here) <optimize.minimize-cg>`\n",
      "            - 'BFGS'        :ref:`(see here) <optimize.minimize-bfgs>`\n",
      "            - 'Newton-CG'   :ref:`(see here) <optimize.minimize-newtoncg>`\n",
      "            - 'L-BFGS-B'    :ref:`(see here) <optimize.minimize-lbfgsb>`\n",
      "            - 'TNC'         :ref:`(see here) <optimize.minimize-tnc>`\n",
      "            - 'COBYLA'      :ref:`(see here) <optimize.minimize-cobyla>`\n",
      "            - 'SLSQP'       :ref:`(see here) <optimize.minimize-slsqp>`\n",
      "            - 'trust-constr':ref:`(see here) <optimize.minimize-trustconstr>`\n",
      "            - 'dogleg'      :ref:`(see here) <optimize.minimize-dogleg>`\n",
      "            - 'trust-ncg'   :ref:`(see here) <optimize.minimize-trustncg>`\n",
      "            - 'trust-exact' :ref:`(see here) <optimize.minimize-trustexact>`\n",
      "            - 'trust-krylov' :ref:`(see here) <optimize.minimize-trustkrylov>`\n",
      "            - custom - a callable object (added in version 0.14.0),\n",
      "              see below for description.\n",
      "    \n",
      "        If not given, chosen to be one of ``BFGS``, ``L-BFGS-B``, ``SLSQP``,\n",
      "        depending if the problem has constraints or bounds.\n",
      "    jac : {callable,  '2-point', '3-point', 'cs', bool}, optional\n",
      "        Method for computing the gradient vector. Only for CG, BFGS,\n",
      "        Newton-CG, L-BFGS-B, TNC, SLSQP, dogleg, trust-ncg, trust-krylov,\n",
      "        trust-exact and trust-constr.\n",
      "        If it is a callable, it should be a function that returns the gradient\n",
      "        vector:\n",
      "    \n",
      "            ``jac(x, *args) -> array_like, shape (n,)``\n",
      "    \n",
      "        where ``x`` is an array with shape (n,) and ``args`` is a tuple with\n",
      "        the fixed parameters. If `jac` is a Boolean and is True, `fun` is\n",
      "        assumed to return and objective and gradient as an ``(f, g)`` tuple.\n",
      "        Methods 'Newton-CG', 'trust-ncg', 'dogleg', 'trust-exact', and\n",
      "        'trust-krylov' require that either a callable be supplied, or that\n",
      "        `fun` return the objective and gradient.\n",
      "        If None or False, the gradient will be estimated using 2-point finite\n",
      "        difference estimation with an absolute step size.\n",
      "        Alternatively, the keywords  {'2-point', '3-point', 'cs'} can be used\n",
      "        to select a finite difference scheme for numerical estimation of the\n",
      "        gradient with a relative step size. These finite difference schemes\n",
      "        obey any specified `bounds`.\n",
      "    hess : {callable, '2-point', '3-point', 'cs', HessianUpdateStrategy}, optional\n",
      "        Method for computing the Hessian matrix. Only for Newton-CG, dogleg,\n",
      "        trust-ncg,  trust-krylov, trust-exact and trust-constr. If it is\n",
      "        callable, it should return the  Hessian matrix:\n",
      "    \n",
      "            ``hess(x, *args) -> {LinearOperator, spmatrix, array}, (n, n)``\n",
      "    \n",
      "        where x is a (n,) ndarray and `args` is a tuple with the fixed\n",
      "        parameters. LinearOperator and sparse matrix returns are\n",
      "        allowed only for 'trust-constr' method. Alternatively, the keywords\n",
      "        {'2-point', '3-point', 'cs'} select a finite difference scheme\n",
      "        for numerical estimation. Or, objects implementing\n",
      "        `HessianUpdateStrategy` interface can be used to approximate\n",
      "        the Hessian. Available quasi-Newton methods implementing\n",
      "        this interface are:\n",
      "    \n",
      "            - `BFGS`;\n",
      "            - `SR1`.\n",
      "    \n",
      "        Whenever the gradient is estimated via finite-differences,\n",
      "        the Hessian cannot be estimated with options\n",
      "        {'2-point', '3-point', 'cs'} and needs to be\n",
      "        estimated using one of the quasi-Newton strategies.\n",
      "        Finite-difference options {'2-point', '3-point', 'cs'} and\n",
      "        `HessianUpdateStrategy` are available only for 'trust-constr' method.\n",
      "    hessp : callable, optional\n",
      "        Hessian of objective function times an arbitrary vector p. Only for\n",
      "        Newton-CG, trust-ncg, trust-krylov, trust-constr.\n",
      "        Only one of `hessp` or `hess` needs to be given.  If `hess` is\n",
      "        provided, then `hessp` will be ignored.  `hessp` must compute the\n",
      "        Hessian times an arbitrary vector:\n",
      "    \n",
      "            ``hessp(x, p, *args) ->  ndarray shape (n,)``\n",
      "    \n",
      "        where x is a (n,) ndarray, p is an arbitrary vector with\n",
      "        dimension (n,) and `args` is a tuple with the fixed\n",
      "        parameters.\n",
      "    bounds : sequence or `Bounds`, optional\n",
      "        Bounds on variables for L-BFGS-B, TNC, SLSQP, Powell, and\n",
      "        trust-constr methods. There are two ways to specify the bounds:\n",
      "    \n",
      "            1. Instance of `Bounds` class.\n",
      "            2. Sequence of ``(min, max)`` pairs for each element in `x`. None\n",
      "               is used to specify no bound.\n",
      "    \n",
      "    constraints : {Constraint, dict} or List of {Constraint, dict}, optional\n",
      "        Constraints definition (only for COBYLA, SLSQP and trust-constr).\n",
      "    \n",
      "        Constraints for 'trust-constr' are defined as a single object or a\n",
      "        list of objects specifying constraints to the optimization problem.\n",
      "        Available constraints are:\n",
      "    \n",
      "            - `LinearConstraint`\n",
      "            - `NonlinearConstraint`\n",
      "    \n",
      "        Constraints for COBYLA, SLSQP are defined as a list of dictionaries.\n",
      "        Each dictionary with fields:\n",
      "    \n",
      "            type : str\n",
      "                Constraint type: 'eq' for equality, 'ineq' for inequality.\n",
      "            fun : callable\n",
      "                The function defining the constraint.\n",
      "            jac : callable, optional\n",
      "                The Jacobian of `fun` (only for SLSQP).\n",
      "            args : sequence, optional\n",
      "                Extra arguments to be passed to the function and Jacobian.\n",
      "    \n",
      "        Equality constraint means that the constraint function result is to\n",
      "        be zero whereas inequality means that it is to be non-negative.\n",
      "        Note that COBYLA only supports inequality constraints.\n",
      "    tol : float, optional\n",
      "        Tolerance for termination. For detailed control, use solver-specific\n",
      "        options.\n",
      "    options : dict, optional\n",
      "        A dictionary of solver options. All methods accept the following\n",
      "        generic options:\n",
      "    \n",
      "            maxiter : int\n",
      "                Maximum number of iterations to perform. Depending on the\n",
      "                method each iteration may use several function evaluations.\n",
      "            disp : bool\n",
      "                Set to True to print convergence messages.\n",
      "    \n",
      "        For method-specific options, see :func:`show_options()`.\n",
      "    callback : callable, optional\n",
      "        Called after each iteration. For 'trust-constr' it is a callable with\n",
      "        the signature:\n",
      "    \n",
      "            ``callback(xk, OptimizeResult state) -> bool``\n",
      "    \n",
      "        where ``xk`` is the current parameter vector. and ``state``\n",
      "        is an `OptimizeResult` object, with the same fields\n",
      "        as the ones from the return. If callback returns True\n",
      "        the algorithm execution is terminated.\n",
      "        For all the other methods, the signature is:\n",
      "    \n",
      "            ``callback(xk)``\n",
      "    \n",
      "        where ``xk`` is the current parameter vector.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    res : OptimizeResult\n",
      "        The optimization result represented as a ``OptimizeResult`` object.\n",
      "        Important attributes are: ``x`` the solution array, ``success`` a\n",
      "        Boolean flag indicating if the optimizer exited successfully and\n",
      "        ``message`` which describes the cause of the termination. See\n",
      "        `OptimizeResult` for a description of other attributes.\n",
      "    \n",
      "    See also\n",
      "    --------\n",
      "    minimize_scalar : Interface to minimization algorithms for scalar\n",
      "        univariate functions\n",
      "    show_options : Additional options accepted by the solvers\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    This section describes the available solvers that can be selected by the\n",
      "    'method' parameter. The default method is *BFGS*.\n",
      "    \n",
      "    **Unconstrained minimization**\n",
      "    \n",
      "    Method :ref:`Nelder-Mead <optimize.minimize-neldermead>` uses the\n",
      "    Simplex algorithm [1]_, [2]_. This algorithm is robust in many\n",
      "    applications. However, if numerical computation of derivative can be\n",
      "    trusted, other algorithms using the first and/or second derivatives\n",
      "    information might be preferred for their better performance in\n",
      "    general.\n",
      "    \n",
      "    Method :ref:`CG <optimize.minimize-cg>` uses a nonlinear conjugate\n",
      "    gradient algorithm by Polak and Ribiere, a variant of the\n",
      "    Fletcher-Reeves method described in [5]_ pp.120-122. Only the\n",
      "    first derivatives are used.\n",
      "    \n",
      "    Method :ref:`BFGS <optimize.minimize-bfgs>` uses the quasi-Newton\n",
      "    method of Broyden, Fletcher, Goldfarb, and Shanno (BFGS) [5]_\n",
      "    pp. 136. It uses the first derivatives only. BFGS has proven good\n",
      "    performance even for non-smooth optimizations. This method also\n",
      "    returns an approximation of the Hessian inverse, stored as\n",
      "    `hess_inv` in the OptimizeResult object.\n",
      "    \n",
      "    Method :ref:`Newton-CG <optimize.minimize-newtoncg>` uses a\n",
      "    Newton-CG algorithm [5]_ pp. 168 (also known as the truncated\n",
      "    Newton method). It uses a CG method to the compute the search\n",
      "    direction. See also *TNC* method for a box-constrained\n",
      "    minimization with a similar algorithm. Suitable for large-scale\n",
      "    problems.\n",
      "    \n",
      "    Method :ref:`dogleg <optimize.minimize-dogleg>` uses the dog-leg\n",
      "    trust-region algorithm [5]_ for unconstrained minimization. This\n",
      "    algorithm requires the gradient and Hessian; furthermore the\n",
      "    Hessian is required to be positive definite.\n",
      "    \n",
      "    Method :ref:`trust-ncg <optimize.minimize-trustncg>` uses the\n",
      "    Newton conjugate gradient trust-region algorithm [5]_ for\n",
      "    unconstrained minimization. This algorithm requires the gradient\n",
      "    and either the Hessian or a function that computes the product of\n",
      "    the Hessian with a given vector. Suitable for large-scale problems.\n",
      "    \n",
      "    Method :ref:`trust-krylov <optimize.minimize-trustkrylov>` uses\n",
      "    the Newton GLTR trust-region algorithm [14]_, [15]_ for unconstrained\n",
      "    minimization. This algorithm requires the gradient\n",
      "    and either the Hessian or a function that computes the product of\n",
      "    the Hessian with a given vector. Suitable for large-scale problems.\n",
      "    On indefinite problems it requires usually less iterations than the\n",
      "    `trust-ncg` method and is recommended for medium and large-scale problems.\n",
      "    \n",
      "    Method :ref:`trust-exact <optimize.minimize-trustexact>`\n",
      "    is a trust-region method for unconstrained minimization in which\n",
      "    quadratic subproblems are solved almost exactly [13]_. This\n",
      "    algorithm requires the gradient and the Hessian (which is\n",
      "    *not* required to be positive definite). It is, in many\n",
      "    situations, the Newton method to converge in fewer iteraction\n",
      "    and the most recommended for small and medium-size problems.\n",
      "    \n",
      "    **Bound-Constrained minimization**\n",
      "    \n",
      "    Method :ref:`L-BFGS-B <optimize.minimize-lbfgsb>` uses the L-BFGS-B\n",
      "    algorithm [6]_, [7]_ for bound constrained minimization.\n",
      "    \n",
      "    Method :ref:`Powell <optimize.minimize-powell>` is a modification\n",
      "    of Powell's method [3]_, [4]_ which is a conjugate direction\n",
      "    method. It performs sequential one-dimensional minimizations along\n",
      "    each vector of the directions set (`direc` field in `options` and\n",
      "    `info`), which is updated at each iteration of the main\n",
      "    minimization loop. The function need not be differentiable, and no\n",
      "    derivatives are taken. If bounds are not provided, then an\n",
      "    unbounded line search will be used. If bounds are provided and\n",
      "    the initial guess is within the bounds, then every function\n",
      "    evaluation throughout the minimization procedure will be within\n",
      "    the bounds. If bounds are provided, the initial guess is outside\n",
      "    the bounds, and `direc` is full rank (default has full rank), then\n",
      "    some function evaluations during the first iteration may be\n",
      "    outside the bounds, but every function evaluation after the first\n",
      "    iteration will be within the bounds. If `direc` is not full rank,\n",
      "    then some parameters may not be optimized and the solution is not\n",
      "    guaranteed to be within the bounds.\n",
      "    \n",
      "    Method :ref:`TNC <optimize.minimize-tnc>` uses a truncated Newton\n",
      "    algorithm [5]_, [8]_ to minimize a function with variables subject\n",
      "    to bounds. This algorithm uses gradient information; it is also\n",
      "    called Newton Conjugate-Gradient. It differs from the *Newton-CG*\n",
      "    method described above as it wraps a C implementation and allows\n",
      "    each variable to be given upper and lower bounds.\n",
      "    \n",
      "    **Constrained Minimization**\n",
      "    \n",
      "    Method :ref:`COBYLA <optimize.minimize-cobyla>` uses the\n",
      "    Constrained Optimization BY Linear Approximation (COBYLA) method\n",
      "    [9]_, [10]_, [11]_. The algorithm is based on linear\n",
      "    approximations to the objective function and each constraint. The\n",
      "    method wraps a FORTRAN implementation of the algorithm. The\n",
      "    constraints functions 'fun' may return either a single number\n",
      "    or an array or list of numbers.\n",
      "    \n",
      "    Method :ref:`SLSQP <optimize.minimize-slsqp>` uses Sequential\n",
      "    Least SQuares Programming to minimize a function of several\n",
      "    variables with any combination of bounds, equality and inequality\n",
      "    constraints. The method wraps the SLSQP Optimization subroutine\n",
      "    originally implemented by Dieter Kraft [12]_. Note that the\n",
      "    wrapper handles infinite values in bounds by converting them into\n",
      "    large floating values.\n",
      "    \n",
      "    Method :ref:`trust-constr <optimize.minimize-trustconstr>` is a\n",
      "    trust-region algorithm for constrained optimization. It swiches\n",
      "    between two implementations depending on the problem definition.\n",
      "    It is the most versatile constrained minimization algorithm\n",
      "    implemented in SciPy and the most appropriate for large-scale problems.\n",
      "    For equality constrained problems it is an implementation of Byrd-Omojokun\n",
      "    Trust-Region SQP method described in [17]_ and in [5]_, p. 549. When\n",
      "    inequality constraints  are imposed as well, it swiches to the trust-region\n",
      "    interior point  method described in [16]_. This interior point algorithm,\n",
      "    in turn, solves inequality constraints by introducing slack variables\n",
      "    and solving a sequence of equality-constrained barrier problems\n",
      "    for progressively smaller values of the barrier parameter.\n",
      "    The previously described equality constrained SQP method is\n",
      "    used to solve the subproblems with increasing levels of accuracy\n",
      "    as the iterate gets closer to a solution.\n",
      "    \n",
      "    **Finite-Difference Options**\n",
      "    \n",
      "    For Method :ref:`trust-constr <optimize.minimize-trustconstr>`\n",
      "    the gradient and the Hessian may be approximated using\n",
      "    three finite-difference schemes: {'2-point', '3-point', 'cs'}.\n",
      "    The scheme 'cs' is, potentially, the most accurate but it\n",
      "    requires the function to correctly handles complex inputs and to\n",
      "    be differentiable in the complex plane. The scheme '3-point' is more\n",
      "    accurate than '2-point' but requires twice as many operations.\n",
      "    \n",
      "    **Custom minimizers**\n",
      "    \n",
      "    It may be useful to pass a custom minimization method, for example\n",
      "    when using a frontend to this method such as `scipy.optimize.basinhopping`\n",
      "    or a different library.  You can simply pass a callable as the ``method``\n",
      "    parameter.\n",
      "    \n",
      "    The callable is called as ``method(fun, x0, args, **kwargs, **options)``\n",
      "    where ``kwargs`` corresponds to any other parameters passed to `minimize`\n",
      "    (such as `callback`, `hess`, etc.), except the `options` dict, which has\n",
      "    its contents also passed as `method` parameters pair by pair.  Also, if\n",
      "    `jac` has been passed as a bool type, `jac` and `fun` are mangled so that\n",
      "    `fun` returns just the function values and `jac` is converted to a function\n",
      "    returning the Jacobian.  The method shall return an `OptimizeResult`\n",
      "    object.\n",
      "    \n",
      "    The provided `method` callable must be able to accept (and possibly ignore)\n",
      "    arbitrary parameters; the set of parameters accepted by `minimize` may\n",
      "    expand in future versions and then these parameters will be passed to\n",
      "    the method.  You can find an example in the scipy.optimize tutorial.\n",
      "    \n",
      "    .. versionadded:: 0.11.0\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Nelder, J A, and R Mead. 1965. A Simplex Method for Function\n",
      "        Minimization. The Computer Journal 7: 308-13.\n",
      "    .. [2] Wright M H. 1996. Direct search methods: Once scorned, now\n",
      "        respectable, in Numerical Analysis 1995: Proceedings of the 1995\n",
      "        Dundee Biennial Conference in Numerical Analysis (Eds. D F\n",
      "        Griffiths and G A Watson). Addison Wesley Longman, Harlow, UK.\n",
      "        191-208.\n",
      "    .. [3] Powell, M J D. 1964. An efficient method for finding the minimum of\n",
      "       a function of several variables without calculating derivatives. The\n",
      "       Computer Journal 7: 155-162.\n",
      "    .. [4] Press W, S A Teukolsky, W T Vetterling and B P Flannery.\n",
      "       Numerical Recipes (any edition), Cambridge University Press.\n",
      "    .. [5] Nocedal, J, and S J Wright. 2006. Numerical Optimization.\n",
      "       Springer New York.\n",
      "    .. [6] Byrd, R H and P Lu and J. Nocedal. 1995. A Limited Memory\n",
      "       Algorithm for Bound Constrained Optimization. SIAM Journal on\n",
      "       Scientific and Statistical Computing 16 (5): 1190-1208.\n",
      "    .. [7] Zhu, C and R H Byrd and J Nocedal. 1997. L-BFGS-B: Algorithm\n",
      "       778: L-BFGS-B, FORTRAN routines for large scale bound constrained\n",
      "       optimization. ACM Transactions on Mathematical Software 23 (4):\n",
      "       550-560.\n",
      "    .. [8] Nash, S G. Newton-Type Minimization Via the Lanczos Method.\n",
      "       1984. SIAM Journal of Numerical Analysis 21: 770-778.\n",
      "    .. [9] Powell, M J D. A direct search optimization method that models\n",
      "       the objective and constraint functions by linear interpolation.\n",
      "       1994. Advances in Optimization and Numerical Analysis, eds. S. Gomez\n",
      "       and J-P Hennart, Kluwer Academic (Dordrecht), 51-67.\n",
      "    .. [10] Powell M J D. Direct search algorithms for optimization\n",
      "       calculations. 1998. Acta Numerica 7: 287-336.\n",
      "    .. [11] Powell M J D. A view of algorithms for optimization without\n",
      "       derivatives. 2007.Cambridge University Technical Report DAMTP\n",
      "       2007/NA03\n",
      "    .. [12] Kraft, D. A software package for sequential quadratic\n",
      "       programming. 1988. Tech. Rep. DFVLR-FB 88-28, DLR German Aerospace\n",
      "       Center -- Institute for Flight Mechanics, Koln, Germany.\n",
      "    .. [13] Conn, A. R., Gould, N. I., and Toint, P. L.\n",
      "       Trust region methods. 2000. Siam. pp. 169-200.\n",
      "    .. [14] F. Lenders, C. Kirches, A. Potschka: \"trlib: A vector-free\n",
      "       implementation of the GLTR method for iterative solution of\n",
      "       the trust region problem\", :arxiv:`1611.04718`\n",
      "    .. [15] N. Gould, S. Lucidi, M. Roma, P. Toint: \"Solving the\n",
      "       Trust-Region Subproblem using the Lanczos Method\",\n",
      "       SIAM J. Optim., 9(2), 504--525, (1999).\n",
      "    .. [16] Byrd, Richard H., Mary E. Hribar, and Jorge Nocedal. 1999.\n",
      "        An interior point algorithm for large-scale nonlinear  programming.\n",
      "        SIAM Journal on Optimization 9.4: 877-900.\n",
      "    .. [17] Lalee, Marucha, Jorge Nocedal, and Todd Plantega. 1998. On the\n",
      "        implementation of an algorithm for large-scale equality constrained\n",
      "        optimization. SIAM Journal on Optimization 8.3: 682-706.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Let us consider the problem of minimizing the Rosenbrock function. This\n",
      "    function (and its respective derivatives) is implemented in `rosen`\n",
      "    (resp. `rosen_der`, `rosen_hess`) in the `scipy.optimize`.\n",
      "    \n",
      "    >>> from scipy.optimize import minimize, rosen, rosen_der\n",
      "    \n",
      "    A simple application of the *Nelder-Mead* method is:\n",
      "    \n",
      "    >>> x0 = [1.3, 0.7, 0.8, 1.9, 1.2]\n",
      "    >>> res = minimize(rosen, x0, method='Nelder-Mead', tol=1e-6)\n",
      "    >>> res.x\n",
      "    array([ 1.,  1.,  1.,  1.,  1.])\n",
      "    \n",
      "    Now using the *BFGS* algorithm, using the first derivative and a few\n",
      "    options:\n",
      "    \n",
      "    >>> res = minimize(rosen, x0, method='BFGS', jac=rosen_der,\n",
      "    ...                options={'gtol': 1e-6, 'disp': True})\n",
      "    Optimization terminated successfully.\n",
      "             Current function value: 0.000000\n",
      "             Iterations: 26\n",
      "             Function evaluations: 31\n",
      "             Gradient evaluations: 31\n",
      "    >>> res.x\n",
      "    array([ 1.,  1.,  1.,  1.,  1.])\n",
      "    >>> print(res.message)\n",
      "    Optimization terminated successfully.\n",
      "    >>> res.hess_inv\n",
      "    array([[ 0.00749589,  0.01255155,  0.02396251,  0.04750988,  0.09495377],  # may vary\n",
      "           [ 0.01255155,  0.02510441,  0.04794055,  0.09502834,  0.18996269],\n",
      "           [ 0.02396251,  0.04794055,  0.09631614,  0.19092151,  0.38165151],\n",
      "           [ 0.04750988,  0.09502834,  0.19092151,  0.38341252,  0.7664427 ],\n",
      "           [ 0.09495377,  0.18996269,  0.38165151,  0.7664427,   1.53713523]])\n",
      "    \n",
      "    \n",
      "    Next, consider a minimization problem with several constraints (namely\n",
      "    Example 16.4 from [5]_). The objective function is:\n",
      "    \n",
      "    >>> fun = lambda x: (x[0] - 1)**2 + (x[1] - 2.5)**2\n",
      "    \n",
      "    There are three constraints defined as:\n",
      "    \n",
      "    >>> cons = ({'type': 'ineq', 'fun': lambda x:  x[0] - 2 * x[1] + 2},\n",
      "    ...         {'type': 'ineq', 'fun': lambda x: -x[0] - 2 * x[1] + 6},\n",
      "    ...         {'type': 'ineq', 'fun': lambda x: -x[0] + 2 * x[1] + 2})\n",
      "    \n",
      "    And variables must be positive, hence the following bounds:\n",
      "    \n",
      "    >>> bnds = ((0, None), (0, None))\n",
      "    \n",
      "    The optimization problem is solved using the SLSQP method as:\n",
      "    \n",
      "    >>> res = minimize(fun, (2, 0), method='SLSQP', bounds=bnds,\n",
      "    ...                constraints=cons)\n",
      "    \n",
      "    It should converge to the theoretical solution (1.4 ,1.7).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(minimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "9927d9fd-6bfe-40c6-bb8d-edf689696301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabColor(lab_l=99.99998453333127,lab_a=-0.0004593894083471106,lab_b=-0.008561457924405325)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_color(sRGBColor(1,1,1), LabColor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "24837ab6-6ee4-4a27-89dd-485560853505",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.805288282313768,\n",
       " 25.25580234400877,\n",
       " 2.0150847086000567,\n",
       " -0.7777250308095063,\n",
       " -0.46180729537184106,\n",
       " 24.499089850903033,\n",
       " -79.58374107350608,\n",
       " 48.13470090912517,\n",
       " -25.58658850518043,\n",
       " 47.34051963212096,\n",
       " 50.61165929707272,\n",
       " -45.927066028562535,\n",
       " 13.971977085085996,\n",
       " -29.1613764711542,\n",
       " -33.754759675287005,\n",
       " 1.8559304955459766,\n",
       " 7.0390977262349,\n",
       " 14.898147010927687,\n",
       " -21.730393594009456,\n",
       " -14.75110105736519,\n",
       " -2.023897871433178,\n",
       " 3.072440574695179,\n",
       " 39.79631617494306,\n",
       " -5.2801186066062655,\n",
       " 4.53005382841809,\n",
       " -4.270033598939449,\n",
       " -9.121722662075626,\n",
       " 2.5856275491491942,\n",
       " -15.324780147679462,\n",
       " 33.347545937087375]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "aa7c704d-8623-4271-b352-50ac93a5f76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e478dcab-be18-4543-9f0a-b4a97f6d2e2c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.55221969, 0.88807475, 0.48498694]),\n",
       " array([0.45221969, 0.98807475, 0.48498694]),\n",
       " array([0.45221969, 0.88807475, 0.58498694]),\n",
       " array([0.17916363, 0.84307152, 0.60840341]),\n",
       " array([0.07916363, 0.94307152, 0.60840341]),\n",
       " array([0.07916363, 0.84307152, 0.70840341]),\n",
       " array([0.35219011, 0.17505316, 0.22348611]),\n",
       " array([0.25219011, 0.27505316, 0.22348611]),\n",
       " array([0.25219011, 0.17505316, 0.32348611]),\n",
       " array([1.06849772, 0.42076737, 0.68864667]),\n",
       " array([0.96849772, 0.52076737, 0.68864667]),\n",
       " array([0.96849772, 0.42076737, 0.78864667]),\n",
       " array([0.57782062, 0.24419521, 0.26092017]),\n",
       " array([0.47782062, 0.34419521, 0.26092017]),\n",
       " array([0.47782062, 0.24419521, 0.36092017]),\n",
       " array([0.91078311, 0.3070404 , 0.98801979]),\n",
       " array([0.81078311, 0.4070404 , 0.98801979]),\n",
       " array([0.81078311, 0.3070404 , 1.08801979]),\n",
       " array([0.54567367, 0.19211148, 0.9953147 ]),\n",
       " array([0.44567367, 0.29211148, 0.9953147 ]),\n",
       " array([0.44567367, 0.19211148, 1.0953147 ]),\n",
       " array([0.36849204, 0.94067574, 0.18614681]),\n",
       " array([0.26849204, 1.04067574, 0.18614681]),\n",
       " array([0.26849204, 0.94067574, 0.28614681]),\n",
       " array([0.54718872, 0.14234202, 0.25236196]),\n",
       " array([0.44718872, 0.24234202, 0.25236196]),\n",
       " array([0.44718872, 0.14234202, 0.35236196]),\n",
       " array([0.86068446, 0.08646759, 0.62321276]),\n",
       " array([0.76068446, 0.18646759, 0.62321276]),\n",
       " array([0.76068446, 0.08646759, 0.72321276])]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labs_d = [np.add(rgb, np.roll([step, 0, 0], i)) for rgb in C for i in [0,1,2]]\n",
    "labs_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d93a15b7-da68-464e-a74f-a85db081f0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4,5]\n",
    "b = [6,7,8,9,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8007a343-7521-42a2-aef0-cb9222ea6e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 8, 4, 5]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:2] + [b[2]] + a[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f264ae97-49ed-4584-9e7c-d33a24989376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 5, 3, 4, 5, 3, 4, 5]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a for l in [0,1,2] for a in [3,4,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e107f71f-3e74-4729-be62-56368e243c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45221969, 0.88807475, 0.48498694],\n",
       "       [0.07916363, 0.84307152, 0.60840341],\n",
       "       [0.25219011, 0.17505316, 0.22348611],\n",
       "       [0.96849772, 0.42076737, 0.68864667],\n",
       "       [0.47782062, 0.24419521, 0.26092017],\n",
       "       [0.81078311, 0.3070404 , 0.98801979],\n",
       "       [0.44567367, 0.19211148, 0.9953147 ],\n",
       "       [0.26849204, 0.94067574, 0.18614681],\n",
       "       [0.44718872, 0.14234202, 0.25236196],\n",
       "       [0.76068446, 0.08646759, 0.62321276]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "51478059-bcd3-430b-a94f-fb398931a55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45221969, 0.88807475, 0.48498694, 0.07916363, 0.84307152,\n",
       "       0.60840341, 0.25219011, 0.17505316, 0.22348611, 0.96849772,\n",
       "       0.42076737, 0.68864667, 0.47782062, 0.24419521, 0.26092017,\n",
       "       0.81078311, 0.3070404 , 0.98801979, 0.44567367, 0.19211148,\n",
       "       0.9953147 , 0.26849204, 0.94067574, 0.18614681, 0.44718872,\n",
       "       0.14234202, 0.25236196, 0.76068446, 0.08646759, 0.62321276])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_points.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "296976f4-64a5-4b66-890b-8ecfcdb2c15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(np.array([[1,0,0], [0,1,0], [0,0,1]])[..., np.newaxis], N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "74bbc296-1832-44e3-ac5e-7ebfd8cf325c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,\n",
       "        16, 17, 18, 19, 20],\n",
       "       [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
       "        37, 38, 39, 40, 41],\n",
       "       [42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57,\n",
       "        58, 59, 60, 61, 62]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(3*21).reshape(3,21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ec0551c5-7c0c-44cc-a245-7f563682d7c2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  0,  0],\n",
       "        [ 1,  1,  1],\n",
       "        [ 2,  2,  2]],\n",
       "\n",
       "       [[ 3,  3,  3],\n",
       "        [ 4,  4,  4],\n",
       "        [ 5,  5,  5]],\n",
       "\n",
       "       [[ 6,  6,  6],\n",
       "        [ 7,  7,  7],\n",
       "        [ 8,  8,  8]],\n",
       "\n",
       "       [[ 9,  9,  9],\n",
       "        [10, 10, 10],\n",
       "        [11, 11, 11]],\n",
       "\n",
       "       [[12, 12, 12],\n",
       "        [13, 13, 13],\n",
       "        [14, 14, 14]],\n",
       "\n",
       "       [[15, 15, 15],\n",
       "        [16, 16, 16],\n",
       "        [17, 17, 17]],\n",
       "\n",
       "       [[18, 18, 18],\n",
       "        [19, 19, 19],\n",
       "        [20, 20, 20]],\n",
       "\n",
       "       [[21, 21, 21],\n",
       "        [22, 22, 22],\n",
       "        [23, 23, 23]],\n",
       "\n",
       "       [[24, 24, 24],\n",
       "        [25, 25, 25],\n",
       "        [26, 26, 26]],\n",
       "\n",
       "       [[27, 27, 27],\n",
       "        [28, 28, 28],\n",
       "        [29, 29, 29]],\n",
       "\n",
       "       [[30, 30, 30],\n",
       "        [31, 31, 31],\n",
       "        [32, 32, 32]],\n",
       "\n",
       "       [[33, 33, 33],\n",
       "        [34, 34, 34],\n",
       "        [35, 35, 35]],\n",
       "\n",
       "       [[36, 36, 36],\n",
       "        [37, 37, 37],\n",
       "        [38, 38, 38]],\n",
       "\n",
       "       [[39, 39, 39],\n",
       "        [40, 40, 40],\n",
       "        [41, 41, 41]],\n",
       "\n",
       "       [[42, 42, 42],\n",
       "        [43, 43, 43],\n",
       "        [44, 44, 44]],\n",
       "\n",
       "       [[45, 45, 45],\n",
       "        [46, 46, 46],\n",
       "        [47, 47, 47]],\n",
       "\n",
       "       [[48, 48, 48],\n",
       "        [49, 49, 49],\n",
       "        [50, 50, 50]],\n",
       "\n",
       "       [[51, 51, 51],\n",
       "        [52, 52, 52],\n",
       "        [53, 53, 53]],\n",
       "\n",
       "       [[54, 54, 54],\n",
       "        [55, 55, 55],\n",
       "        [56, 56, 56]],\n",
       "\n",
       "       [[57, 57, 57],\n",
       "        [58, 58, 58],\n",
       "        [59, 59, 59]],\n",
       "\n",
       "       [[60, 60, 60],\n",
       "        [61, 61, 61],\n",
       "        [62, 62, 62]]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(3*21).reshape(21,3)[..., np.newaxis].repeat(3, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1d7e1ca1-84f7-4675-a9c0-bcd4345839d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = rgb_points\n",
    "N = C.size//3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7a2de700-baab-416d-adf3-53e49e18f7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3d1bb7a0-9d9d-4c69-990c-cdcc9a1a3631",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onecol = np.tile([[1,0,0],[0,1,0],[0,0,1]], [N,1])\n",
    "onecol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "57d05559-56fd-4e05-b187-c8a0da199758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C_d = C.repeat(3, axis=0) + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "73302451-6f6e-45de-abf2-6bafe0ee53cc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function repeat in module numpy:\n",
      "\n",
      "repeat(a, repeats, axis=None)\n",
      "    Repeat elements of an array.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array.\n",
      "    repeats : int or array of ints\n",
      "        The number of repetitions for each element.  `repeats` is broadcasted\n",
      "        to fit the shape of the given axis.\n",
      "    axis : int, optional\n",
      "        The axis along which to repeat values.  By default, use the\n",
      "        flattened input array, and return a flat output array.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    repeated_array : ndarray\n",
      "        Output array which has the same shape as `a`, except along\n",
      "        the given axis.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    tile : Tile an array.\n",
      "    unique : Find the unique elements of an array.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.repeat(3, 4)\n",
      "    array([3, 3, 3, 3])\n",
      "    >>> x = np.array([[1,2],[3,4]])\n",
      "    >>> np.repeat(x, 2)\n",
      "    array([1, 1, 2, 2, 3, 3, 4, 4])\n",
      "    >>> np.repeat(x, 3, axis=1)\n",
      "    array([[1, 1, 1, 2, 2, 2],\n",
      "           [3, 3, 3, 4, 4, 4]])\n",
      "    >>> np.repeat(x, [1, 2], axis=0)\n",
      "    array([[1, 2],\n",
      "           [3, 4],\n",
      "           [3, 4]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.repeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "91349e02-03e2-4a3e-95b0-c35904474d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100.0, 100.0, 100.0)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sRGBColor(*(100,100,100), is_upscaled=False).get_value_tuple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "10c727d7-b3ff-40b7-8674-f0bca23cdb35",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class sRGBColor in module colormath.color_objects:\n",
      "\n",
      "class sRGBColor(BaseRGBColor)\n",
      " |  sRGBColor(rgb_r, rgb_g, rgb_b, is_upscaled=False)\n",
      " |  \n",
      " |  Represents an sRGB color.\n",
      " |  \n",
      " |  .. note:: If you pass in upscaled values, we automatically scale them\n",
      " |      down to 0.0-1.0. If you need the old upscaled values, you can\n",
      " |      retrieve them with :py:meth:`get_upscaled_value_tuple`.\n",
      " |  \n",
      " |  :ivar float rgb_r: R coordinate\n",
      " |  :ivar float rgb_g: G coordinate\n",
      " |  :ivar float rgb_b: B coordinate\n",
      " |  :ivar bool is_upscaled: If True, RGB values are between 1-255. If False,\n",
      " |      0.0-1.0.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      sRGBColor\n",
      " |      BaseRGBColor\n",
      " |      ColorBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  conversion_matrices = {'rgb_to_xyz': array([[0.412424 , 0.357579 , 0.1...\n",
      " |  \n",
      " |  native_illuminant = 'd65'\n",
      " |  \n",
      " |  rgb_gamma = 2.2\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseRGBColor:\n",
      " |  \n",
      " |  __init__(self, rgb_r, rgb_g, rgb_b, is_upscaled=False)\n",
      " |      :param float rgb_r: R coordinate. 0...1. 1-255 if is_upscaled=True.\n",
      " |      :param float rgb_g: G coordinate. 0...1. 1-255 if is_upscaled=True.\n",
      " |      :param float rgb_b: B coordinate. 0...1. 1-255 if is_upscaled=True.\n",
      " |      :keyword bool is_upscaled: If False, RGB coordinate values are\n",
      " |          beteween 0.0 and 1.0. If True, RGB values are between 1 and 255.\n",
      " |  \n",
      " |  get_rgb_hex(self)\n",
      " |      Converts the RGB value to a hex value in the form of: #RRGGBB\n",
      " |      \n",
      " |      :rtype: str\n",
      " |  \n",
      " |  get_upscaled_value_tuple(self)\n",
      " |      Scales an RGB color object from decimal 0.0-1.0 to int 0-255.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from BaseRGBColor:\n",
      " |  \n",
      " |  new_from_rgb_hex(hex_str) from builtins.type\n",
      " |      Converts an RGB hex string like #RRGGBB and assigns the values to\n",
      " |      this sRGBColor object.\n",
      " |      \n",
      " |      :rtype: sRGBColor\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseRGBColor:\n",
      " |  \n",
      " |  clamped_rgb_b\n",
      " |      The clamped (0.0-1.0) B value.\n",
      " |  \n",
      " |  clamped_rgb_g\n",
      " |      The clamped (0.0-1.0) G value.\n",
      " |  \n",
      " |  clamped_rgb_r\n",
      " |      The clamped (0.0-1.0) R value.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from BaseRGBColor:\n",
      " |  \n",
      " |  VALUES = ['rgb_r', 'rgb_g', 'rgb_b']\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ColorBase:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      String representation of the object.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      String representation of the color.\n",
      " |  \n",
      " |  get_value_tuple(self)\n",
      " |      Returns a tuple of the color's values (in order). For example,\n",
      " |      an LabColor object will return (lab_l, lab_a, lab_b), where each\n",
      " |      member of the tuple is the float value for said variable.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from ColorBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sRGBColor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d8bab8-0a61-4318-bc58-a75bc79c940a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
